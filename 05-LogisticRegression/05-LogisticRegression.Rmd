---
title: "BIOSTAT702 R Tutorial 5: "
subtitle: "Simple Logistic Regression"
author: "Marissa Ashner, PhD"
date: "Last Updated: 2024-08-22"
output: 
  html_document:
    theme: cosmo
    fig_width: 7
    fig_height: 5
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
---

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}
h1.title{
  font-size: 30px;
  font-weight: bold;
  margin-bottom: 0px;
}
h1 {
  font-size: 20px;
}
h2{
  font-size: 16px;
}
h3.subtitle {
  font-size: 25px;
  font-style: italic;
  margin-top: 3px;
}
h3{
  font-size: 14px;
}
h4{
  font-size: 13px;
}
body, code.r, pre{
  font-size: 12px;
}
```


```{r setup, include=FALSE}
# setting global options for code chunks
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE)
```

This tutorial will follow closely with parts of Chapter 6 in the [textbook](https://bookdown.org/rwnahhas/RMPH/datasumm.html).

# Packages 

The following code loads the packages you need for the tutorial.

```{r, message = FALSE}
## NOTE: If you do not have a package installed, you must install it first
# For example, you can run the following code if you don't have the gtsummary package:
# install.packages("gtsummary")


# for navigating within the R project
library(here)

# for data wrangling 
library(tidyverse)

# for nice-looking tables 
library(gtsummary)

# for hypothesis testing / summaries / diagnostics
library(car)
library(ResourceSelection)

# C statistic 
library(DescTools)
```

# Load Data 

The dataset used for this tutorial is loaded here.

```{r}
# Load Data 
# will be called "nsduh_adult_sub" in your environment 
load(here("data/nsduh2019_adult_sub_rmph.RData"))

# rename dataset for convenience 
nsduh <- nsduh_adult_sub
```

# Logistic Regression with One Binary Predictor

Using the 2019 National Survery of Drug Use and Health (NSDUH) teaching dataset, we want to look at the odds ratio of lifetime marijuana use `mj_lifetime` between males and females `demog_sex`. 

## Visualizing the Data 

Instead of visualizing this data with a plot, we can simply look at a 2 x 2 table. 

```{r}
table(nsduh$demog_sex, nsduh$mj_lifetime)
```

## Running the Model 

We can use the `glm()` function with the argument `family = binomial` to fit a logistic regression model. Similar to a SLR, we can output the results using the `summary()` function.

Note that the parameter estimates are on the log-odds scale and would need to be exponentiated to get the odds ratios. Note that the intercept corresponds to the odds for the reference group and is not an odds ratio itself. 

```{r}
# run the model
fit1 = glm(mj_lifetime ~ demog_sex,
           family = binomial, 
           data = nsduh)

# output the results
summary(fit1)
```

## Confidence Intervals 

Again, similar to SLR, we can use the `confint()` function to obtain confidence intervals for the regression coefficients. These can be exponentiated to get the CI for the odds ratio.

```{r, message = FALSE}
# CI for regression coefficients 
confint(fit1)

# CI for odds ratio
exp(confint(fit1))[-1, , drop=F]
```

We also note that the `S()` function in the `car` package automatically computes confidence intervals for the exponentiated coefficients. 

```{r}
S(fit1)
```

## Hypothesis Tests 

The `summary()` and `S()` functions output the Wald-type hypothesis tests for each of the regression coefficients. You can also output these or the likelihood ratio hypothesis test results using the `Anova()` function in the `car` package. 

```{r}
Anova(fit1, type = 3, test.statistic = "Wald")

Anova(fit1, type = 3, test.statistic = "LR")
```


In order to compare the full and reduced model, we can use `anova()` with the argument `test = "Chisq"`.

```{r}
anova(fit1, test = "Chisq")
```

## Prediction 

As with SLR, the `predict()` function can be used to get predicted values from the model. The default output is on the log-odds scale, but using the argument `type = "response"` will result in a predicted probability instead.

```{r}
# predict probability of lifetime marijuana use for a male 
predict(fit1, 
        newdata = data.frame(demog_sex = "Male"), 
        type = "response")
```

## Assessing Overall Model Fit 

### C Statistic

You can calculate the C statistic using the `Cstat()` function in the `DescTools` package. 

```{r}
Cstat(fit1)
```


# Logistic Regression with One Continuous Predictor 

Now, we want to determine the association between lifetime marijuana use and age at first use of alcohol `alc_agefirst`.

## Visualizing the Data 

We can visualize this data using a binned scatterplot. 

```{r}
# remove NA 
nsduh_cc = nsduh[complete.cases(nsduh$alc_agefirst),]

# break the predictor into quantiles
BREAKS = quantile(nsduh_cc$alc_agefirst, probs = seq(0, 1, length = 8))
X.CUT   = cut(nsduh_cc$alc_agefirst, breaks = BREAKS, include.lowest = T, ordered_result = T)
  
# Average proportion of observed outcome in each bin on logit scale
Y.logit = tapply(nsduh_cc$mj_lifetime %>% as.numeric()-1, list(X.CUT), 
                 function(x) log(mean(x)/(1-mean(x))))

# Average age at first use of alcohol in each bin
X.avg = tapply(nsduh_cc$alc_agefirst, list(X.CUT), mean)

# plot 
ggplot(data.frame(X.avg, Y.logit), aes(X.avg, Y.logit)) + 
  geom_point()
```


## Running the Model 

We can run the model and view the output in the same way as before. 

```{r}
fit2 = glm(mj_lifetime ~ alc_agefirst, 
           family = binomial, 
           data = nsduh)

summary(fit2)
```

## Assessing Overall Model Fit 

### Hosmer and Lemeshow Goodness of Fit Test

The HL test can be run in R using the `hoslem.test()` function from the `ResourceSelection` package. The function automatically uses 10 bins to calculate the quantiles, but this can be altered.

```{r}
HL <- hoslem.test(fit2$y, 
            fit2$fitted.values, 
            g = 8)
HL
```

### Calibration Plot 

You can create a calibration plot that corresponds to the HL test to visualize the relationship between the observed and expected values. This code is inspired by the code in the textbook. 

```{r}
# Bin the expected values into g equal size groups
# using quantiles
# g + 1 breaks leads to g bins
g = 8
BREAKS = quantile(fit2$fitted.values, probs = seq(0, 1, length = g + 1))
Y.CUT   = cut(fit2$fitted.values, breaks = BREAKS, include.lowest = T, ordered_result = T)
  
# Average estimated proportions in each bin
P.EXP = tapply(fit2$fitted.values, list(Y.CUT), mean)

# Proportion of observed outcome = 1 values in each bin
P.OBS = tapply(fit2$y, list(Y.CUT), mean)

# Number of observed outcome = 1 values in each bin
X = as.numeric(tapply(fit2$y, list(Y.CUT), sum))
  
# Size of each bin
N  = as.numeric(tapply(fit2$y, list(Y.CUT), length))

# CI for P.OBS
CI <- vector("list", length(N))
for(i in 1:length(N)) CI[[i]] <- as.numeric(binom.test(X[i], N[i])$conf.int)

# create data frame for plot 
data_calibrationplot = data.frame(P.EXP = P.EXP,
                                  P.OBS = P.OBS) %>% 
  cbind(do.call(rbind, CI))

# plot 
ggplot(data = data_calibrationplot, aes(P.EXP, P.OBS)) + 
  geom_point(pch = 2, size = 4) +
  geom_abline(aes(color = "Perfect", intercept = 0, slope = 1), lty = 2, size = 1.5) + 
  geom_smooth(aes(color = "Observed"), se = FALSE) + 
  geom_errorbar(aes(ymin = `1`, ymax = `2`), width = 0) + 
  xlim(c(0,1)) + ylim(c(0,1)) + 
  labs(x = "Average Predicted Probability", 
       y = "Observed Proportion", 
       title= "Calibration Plot") +   
  scale_color_manual(name = "Legend", 
                     values = c("Perfect" = "darkgray", "Observed" = "black")) +
  theme(legend.position = "top")
```

# Logistic Regression with Two Categorical Predictors 

Now, we want to look at the association of gender and lifetime marijuana use, stratified by lifetime cigarette use `cig_lifetime`. 

## Visualizing the Data 

We can visualize this data using a pair of 2 x 2 tables.

```{r}
table(nsduh$demog_sex, nsduh$mj_lifetime, nsduh$cig_lifetime)
```


## Running the Model 

In order to run this model, we can include the main effects and interaction term separately (using the `:`), or include them all together (using the `*`). 

```{r}
fit3 = glm(mj_lifetime ~ demog_sex*cig_lifetime, 
           family = binomial, 
           data = nsduh)

summary(fit3)
```


# Testing Assumptions / Diagnostics

## Assumptions 

Logistic regression assumes independent observations, which is evaluated by thinking about how the data were collected. Logistic regression does not include an error term and therefore has no assumptions of normally distributed errors or errors with constant variance. Logistic regression does still assume that continuous predictors have a linear relationship with the log-odds of probability of the outcome. 

As with SLR, we can use the `crPlots` from the `car` package to investigate this assumption. 

```{r}
crPlots(fit2, terms = ~alc_agefirst, 
        smooth = list(smoother=gamLine))
```

## Outliers 

The residuals for logistic regression are called deviance residuals and are more complex than the observed minus predicted. The same residual functions as for SLR, however, can calculate the deviance residuals. We can use `resid()`, `rstandard()`, and `rstudent()`. 

We can examine outliers by looking at observations poorly fit by the model on a residual plot. 

```{r}
residualPlots(fit2, terms = ~1, 
              tests = F, quadratic = F, fitted = T, 
              type = "rstudent")
```

## Influential Observations 

Checking influential observations for logistic regression is the same as in SLR. We can plot Cook's distances and dfbetas to examine the influence of the observations. 

```{r}
influenceIndexPlot(fit2, vars = "Cook")
```

```{r}
dfbetas_fit = dfbetas(fit2)

plot(dfbetas_fit[, "alc_agefirst"])
```




# Session information

```{r echo = FALSE, results = 'markup'}
sessionInfo()
```

