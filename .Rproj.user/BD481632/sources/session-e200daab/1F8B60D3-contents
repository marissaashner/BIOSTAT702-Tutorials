---
title: 'BIOSTAT 713: Module Exercise Key'
author: 'Dr. Marissa Ashner'
institute: 'Department of Biostatistics and Bioinformatics'
date: 'Fall 2024'
output: 
  beamer_presentation: 
    latex_engine: xelatex
    keep_tex: true
header-includes: 
  - \titlegraphic{\includegraphics[width=0.3\paperwidth]{../latex_dependencies/duke_som_pic.png}}
  - "\\usepackage{fontspec}"
  - "\\definecolor{dukeblue}{HTML}{003087}"
  - "\\setsansfont{Times New Roman}"
  - "\\setbeamercolor{structure}{fg=dukeblue}"
  - "\\setbeamercolor{title}{fg=dukeblue}"
  - "\\setbeamertemplate{navigation symbols}{}"
  - "\\setbeamertemplate{footline}[frame number]"
  - "\\usepackage{booktabs}"
---


```{r setup, echo=FALSE, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(warning=FALSE, fig.width=5, fig.height=3.5)


##########################################################################
##                                                                        ##
##  Author: Marissa Ashner, marissa.ashner@duke.edu                     
##
##  Program: BIOSTAT713_ModuleExerciseKey.rmd                            ##
##  Purpose: This program performs analyses to support class notes
##    
##                                                                        ##
##  Input files:  XXX                                       
##
##                                                                        ##
##  Output files: BIOSTAT713_ModuleExerciseKey.pdf                      ##
##                                                                        ##
##  Change Log:                                                           ##
##  07/16/2024 File started                     
##  07/22/2024 Added Module Exercises 9, 10
##  ?? Added Module Exercises 11, 12, 14
##  08/05/2024 Added Module Exercises 15
##  08/13/2024 Added Module Exercises 16
##  08/15/2024 Added Module Exercises 17
##                                                                        ##
########################################################################## 

# setwd()
library(tidyverse)
library(ggplot2)
library(cowplot)
library(lubridate)
library(knitr)
library(survival)
library(survminer)
library(asaur)
library(Hmisc)
library(doBy)
library(adjustedCurves)
library(flexsurv)

options(knitr.kable.NA="")
options(max.print = .Machine$integer.max)  # don't limit console printing

rm(list=ls())
```


# Module 1 -- Paper 1

\begin{enumerate}
\item 3-year event free survival (time until tumor progression or death of any cause) and 3-year overall survival (time until death of any cause) 
\item Start of neoadjuvant therapy
\item They mention a data cut-off on Sept 30, 2021 but otherwise unclear. Was it the case that everyone was censored on that date, but they all started at different times, leading to different censoring times? 
\item Unclear overall, but for the data cut-off, that administrative censoring would probably be non-informative
\end{enumerate}

# Module 1 -- Paper 2

\begin{enumerate}
\item Overall survival (time to death from other causes) and prostate cancer-specific survival (time to death from prostate cancer)
\item Cancer diagnosis (could be made more clear)
\item Mentions they were followed up until Dec 31, 2007; no mention of anyone lost to follow up
\item The administrative censoring would be non-informative, but unclear if other reasons for censoring are also at play 
\end{enumerate}

# Module 1 -- Paper 3

\begin{enumerate}
\item Time to intubation (Start of first attempt of insertion of the laryngoscope until a capnogram signal was obtained)
\item Start of first attempt of insertion of the laryngoscope
\item For patients who crossed over to the other method or whose tracheas were intubated after 100 seconds, censoring was defined at the technique crossing point of 100 seconds 
\item They do not discuss, but I would think censoring would be informative since it reflects the outcome (time to intubation) 
\end{enumerate}

# Module 2 -- Exponential 

\begin{enumerate}
\item $S(t) = e^{-\lambda t}$
\item $h(t) = \lambda$
\item $H(t) = \lambda t$
\end{enumerate}

# Module 2 -- Weibull 

\begin{enumerate}
\item $S(t) = e^{-(\lambda t)^p}$
\item $h(t) = p\lambda^pt^{p-1}$
\item $H(t) = (\lambda t)^p$
\end{enumerate}

# Module 2 -- Uniform

\begin{enumerate}
\item $S(t) = 1-\frac{t}{10}$
\item $h(t) = \frac{1}{10-t}$
\item $H(t) = -\log\left(1-\frac{t}{10}\right)$
\end{enumerate}

# Module 3

```{r, echo = FALSE}
intervals = c("[0,1)", "[1,2)", "[2,7)", "[7,9)", "[9,13)", "[13,\\infty)")
nt = c(10, 10, 9, 6, 4, 1)
dt = c(0, 1, 1, 1, 2, 1)
ct = c(0, 0, 2, 1, 1, 0)
St = round(cumprod((nt-dt)/nt), 2)
kableExtra::kable(data.frame(intervals, nt, dt, ct, St), 
                  col.names = c("t", "$n_t$", "$d_t$", "$c_t$", "$\\hat{S}(t)$"),
                  format = "latex", escape = FALSE, 
                  booktabs = TRUE, linesep = "", align = "c") %>% 
    kableExtra::kable_styling(position = "center")
```

# Module 4 -- KM Curve

\tiny

```{r,  out.width="80%", out.height="60%"}
mod4 = data.frame(time = c(1, 2, 4, 5, 7, 8, 9, 9, 11, 13), 
                  event = c(1, 1, 0, 0, 1, 0, 1, 1, 0, 1))
mod4_km = survfit(Surv(time, event) ~ 1, data = mod4)

# Plotting KM curve using ggsurvplot
ggsurvplot(mod4_km, data = mod4,
           conf.int = TRUE, # note these are pointwise CI
           risk.table = TRUE,
           tables.height = 0.35,
           legend = "none")
```

\normalsize

# Module 4 -- NA Estimates

\tiny

```{r}
mod4_na = survfit(Surv(time, event) ~ 1, data = mod4, 
                  stype = 2,
                  ctype = 1)
summary(mod4_na)
```

\normalsize

# Module 9 -- \# 1 Code

\tiny

```{r}
data("pharmacoSmoking")

# create survival object 
surv_obj_ps = Surv(pharmacoSmoking$ttr, pharmacoSmoking$relapse)

# create the additional rcs covariates (3 knots means 3-2 = 1 additional covariate)
spline_cov = rcspline.eval(pharmacoSmoking$yearsSmoking, nk = 3, norm = 0)

# save the knot locations
knots = attr(spline_cov, "knots") 

# fit the cox regression
cox_module9 = coxph(surv_obj_ps ~ grp*levelSmoking + yearsSmoking + 
                      rcspline.eval(yearsSmoking, knots, norm=0),
                           data = pharmacoSmoking)
```

\normalsize 

# Module 9 -- \# 1 Output 

\tiny

```{r}
summary(cox_module9)
```

\normalsize

# Module 9 -- \# 2 

No, the hypothesis test of the interaction term `grppatchOnly:levelSmokinglight` shows no evidence that there is modification of the treatment effect by level of smoking ($p = 0.4399$). 

# Module 9 -- \# 3

No, the hypothesis test of the additional restricted cubic spline term shows no evidence that there is a non-linear relationship between years smoking and the log hazard of relapse ($p = 0.8892$). 

# Module 9 -- \# 4 Set-up

**Model:** 

$$\log(h(t)/h_0(t)) = \beta_1*X_{\text{grp}} + \beta_2*X_{\text{level}} + \beta_3*X_{\text{years}} + \beta_4*X_{\text{rcs}} + \beta_5*X_{\text{grp:level}}$$

**Participant 1:** patch Only, light smoking, 25 years of smoking

$$\log(h_1(t)/h_0(t)) = \beta_1 + \beta_2 + \beta_3*25 + \beta_4*f_{\text{rcs}}(25) + \beta_5$$

**Participant 2:** combination, light smoking, 25 years of smoking

$$\log(h_2(t)/h_0(t)) = \beta_2 + \beta_3*25 + \beta_4*f_{\text{rcs}}(25)$$
**Hazard Ratio:**

$$\log(h_1(t)/h_2(t)) = \beta_1 + \beta_5$$

# Module 9 -- \# 4 Code and Output 

\tiny

```{r}
### Create the L matrix
L = rbind(
c(1, 0, 0, 0, 1)
)

### Run the contrast
patch_v_combo = esticon(cox_module9, L, conf.int=TRUE)

### Exponentiate to get hazard ratios
paste0("Hazard Ratio for Patch Only vs Combination (Light Smoking, 25 Years smoking): ",
round(exp(patch_v_combo$estimate), 2), " (",
round(exp(patch_v_combo$lwr), 2), ", ",
round(exp(patch_v_combo$upr), 2), ")")
```

\normalsize

# Module 9 -- \# 4 Interpretation 

For two participants with light smoking and 25 years of smoking, the estimated hazard for a participant with the patch only treatment is 2.3 times as high as the estimated hazard for a participants with the combination treatment. We are 95\% confident this hazard ratio lies between 1.05 and 5.05. Therefore, there is evidence that the combination treatment has benefit over the patch only treatment for those with light smoking and 25 years of smoking. 

# Module 10 -- \# 1 

\tiny

```{r}
data("pharmacoSmoking")

# create survival object 
surv_obj_ps = Surv(pharmacoSmoking$ttr, pharmacoSmoking$relapse)

# fit the cox regression
cox_module10 = coxph(surv_obj_ps ~ grp + yearsSmoking + strata(levelSmoking),
                           data = pharmacoSmoking)
summary(cox_module10)
```
\normalsize 

# Module 10 -- \# 2

Yes, there is evidence of a treatment effect on hazard within each level of smoking, controlling for years smoking (p = 0.00697). The estimate of the hazard ratio is 1.7979, indicating that the risk of relapse is greater in the patch only treatment group, compared to the combination treatment group. We are 95\% confident the true hazard ratio lies between 1.1741 and 2.753.

# Module 10 -- \# 3

No, since we are stratifying on level of smoking, that means we are assuming a different baseline hazard for the two levels of smoking. Therefore, we cannot calculate the hazard ratio between those groups, since the baseline hazards will not cancel out and there is no estimate in the regression output.

# Module 10 -- \# 4 without CI

\tiny

```{r, out.width="80%", out.height="60%"}
ggadjustedcurves(cox_module10, variable = "grp", 
                 data = pharmacoSmoking)
```

\normalsize 

# Module 10 -- \# 4 with CI (not required)

\tiny

```{r, message = FALSE, out.width="80%", out.height="60%"}
adjusted_curv = adjustedsurv(data = pharmacoSmoking, variable = "grp",
                    ev_time = "ttr", event = "relapse", 
                    method = "direct", 
                    outcome_model = coxph(Surv(ttr, relapse) ~ 
                                            grp + yearsSmoking + strata(levelSmoking),
                           data = pharmacoSmoking, x = TRUE),
                    conf_int = TRUE)
plot(adjusted_curv, conf_int = TRUE)
```

\normalsize

# Module 11 -- \# 1 

\tiny

```{r, out.width="80%", out.height="60%"}
data("pharmacoSmoking")

### assessing the PH assumption for the levelSmoking covariate
surv_plot = ggsurvplot(survfit(Surv(ttr, relapse) ~ levelSmoking,
data = pharmacoSmoking), data = pharmacoSmoking)

ggplot(data = surv_plot$data.survplot,
aes(log(time), log(-log(surv)), color = levelSmoking)) + 
  geom_point() + geom_path()
```

From this plot, the lines appear to cross twice, implying that the proportional hazards assumption may not hold.

\normalsize

# Module 11 -- \# 2 

\tiny 

```{r, out.width="80%", out.height="60%"}
## fit the cox model
cox_levelSmoking = coxph(Surv(ttr, relapse) ~ levelSmoking,
                data = pharmacoSmoking)

## plot schoenfeld residuals and run global hypothesis test
ggcoxzph(cox.zph(cox_levelSmoking))
```

From this plot and hypothesis test, there is no evidence that the proportional hazards assumption is violated. 

\normalsize

# Module 11 -- \# 3 

I would tell the investigators that based on the evidence from these two methods, the proportional hazards assumption is not grossly violated for the `levelSmoking` variable. Even though the lines cross twice in the log-log plot, the crosses are not substantial and overall the lines are similar and roughly parallel. Additionally, there is no evidence of violation from the scaled schoenfeld residuals analysis. 

While it wouldn't be wrong to add stratification, a model without stratification is easier to interpret, especially if it is of interest to compare the hazard between different levels of smoking. 

# Module 12 -- \# 1 

\tiny

```{r, warnings = FALSE, out.width="80%", out.height="60%"}
data("pharmacoSmoking")

ggcoxfunctional(Surv(ttr, relapse) ~ yearsSmoking, 
                data = pharmacoSmoking, ylim = c(-2, 1))
```

\small 

There doesn't appear to be an obvious non-linear pattern in the plot, and therefore there isn't strong evidence from the plot that the linearity assumption doesn't hold. 

\normalsize

# Module 14 -- \# 1 Set up the Data 

\scriptsize

```{r}
# load dataset 
load("../Teaching Datasets/Core Temperature/Core_Temperature.Rdata")

# select needed variables
coretemp = Core_Temperature %>% select(LOS, DEAD, TWATemp, Open) %>%
mutate(event = 1-DEAD) %>%
select(-DEAD)

# create survival object 
surv_coretemp = Surv(coretemp$LOS, coretemp$event)

## fit the original cox model
cox_coretemp = coxph(surv_coretemp ~ TWATemp + Open,
data = coretemp)
```

# Module 14 -- \# 1 Explore the Schoenfeld Residuals (Default)

\tiny

```{r,  out.width="80%", out.height="60%"}
# plot the schoenfeld residuals for the Open Variable 
ggcoxzph(cox.zph(cox_coretemp))$`2`
```

# Module 14 -- \# 2 Explore the Schoenfeld Residuals (Identity)

\tiny

```{r,  out.width="80%", out.height="60%", message = FALSE}
# use the identity transform to see how the residuals change with time on the original time scale 
ggcoxzph(cox.zph(cox_coretemp, transform = "identity"))$`2` +
  xlim(c(0,100)) + # zoom in a little bit to see more
  ylim(c(-20,20))
```

# Module 14 -- \# 3 Time Dependent Covariates (Option 1)

\scriptsize

```{r}
# use survSplit to cut the data at the event times, and add two TDC for the piecewise functions
coretemp_survSplit = survSplit(Surv(LOS, event) ~., 
                             data = coretemp,
                             # cut at the unique event times
                             cut = unique(coretemp$LOS[coretemp$event == 1]), 
                             id = "id") %>% 
  # create the new Open Variables
  mutate(open_tdc1 = Open*I(LOS <= 15), 
         open_tdc2 = Open*I(LOS > 15))

# run the cox model using both of the TDC and not using the original open variable
cox_coretemp_tdc = coxph(Surv(tstart, LOS, event) ~ TWATemp + open_tdc1 + 
                           open_tdc2,
data = coretemp_survSplit)
```

# Module 14 -- \# 3 Time Dependent Covariates (Option 1)

\tiny

```{r}
summary(cox_coretemp_tdc)
```

# Module 14 -- \# 4 Check the Proportional Hazards Assumption (Option 1)

\scriptsize

```{r}
cox.zph(cox_coretemp_tdc)
```

# Module 14 -- \# 3 Time Dependent Covariates (Option 2)

\scriptsize

```{r}
# use survSplit to cut the data at time 15, and use the episode argument to 
# add a variable for each time interval
coretemp_survSplit_2 = survSplit(Surv(LOS, event) ~., 
                             data = coretemp,
                             # cut at time 15
                             cut = c(15),
                             # name the new variable
                             episode = "open_tdc",
                             id = "id")

# convert new variable to factor
coretemp_survSplit_2$open_tdc = as.factor(coretemp_survSplit_2$open_tdc)

# run the cox model using the interaction between open and the new variable 
# not using the original open variable
cox_coretemp_tdc_2 = coxph(Surv(tstart, LOS, event) ~ TWATemp + Open:open_tdc,
data = coretemp_survSplit_2)
```

# Module 14 -- \# 3 Time Dependent Covariates (Option 2)

\tiny

```{r}
summary(cox_coretemp_tdc_2)
```

# Module 14 -- \# 4 Check the Proportional Hazards Assumption (Option 2)

\scriptsize

```{r}
cox.zph(cox_coretemp_tdc_2)
```

# Module 15 -- \# 1 

-   Because the distributions are exponential, then $S(t) = \exp(-\lambda t)$
-   $0.7 \exp(-\lambda_A*12) \implies \lambda_A = -\log(0.7)/12$
-   $0.6 \exp(-\lambda_B*12) \implies \lambda_B = -\log(0.6)/12$

\scriptsize 

```{r}
lambdaA = -log(0.7)/12
lambdaB = -log(0.6)/12
HR = lambdaA/lambdaB
HR
```

# Module 15 -- \# 2 

-   As we covered in class, when we have median survival times, the hazard ratio is $m_B/m_A$

\scriptsize

```{r}
HR = 6/9
HR
```

# Module 15 -- \# 3 

\tiny

```{r}
## Calculate the proportion of patients expected to die during follow up
lambdaB = 2
lambdaA = 1
HR = lambdaA/lambdaB
f = 3
a = 1
pA = 2/3
S = function(t){(1-pA)*exp(-lambdaB*t) + pA*exp(-lambdaA*t)}
propDeaths = 1 - 1/6*(S(f) + 4*S(f+0.5*a) + S(f+a))

## calculate the sample size 
survivalpwr::pwr_coxph(power = 0.9,
                       stddev = sqrt(pA*(1-pA)), 
                       hr = HR, 
                       eventprob = propDeaths)
```


# Module 16 -- \# 1

$$S(t) = S_0(t/\phi) = e^{-((t/\phi)/b)^a} = e^{-(t/(b\phi))^a}$$

This is a Weibull distribution with shape $a$ and scale $b\phi$.

The hazard function is 

\begin{align*}
h(t) &= f(t)/S(t) = (a/b\phi)(t/b\phi)^{a-1}e^{-(t/(b\phi))^a}/e^{-(t/(b\phi))^a} \\
&= (a/b\phi)(t/b\phi)^{a-1}
\end{align*}

# Module 16 -- \# 2 

\begin{align*}
h(t) &= h_0(t)g(\mathbf{Z}) = (a/b)(t/b)^{a-1}g(\mathbf{Z}) \\
&= at^{a-1}b^{-a}g(\mathbf{Z}) \\
&= at^{a-1}(bg(.)^{-1/a})^{-a}
\end{align*}

This is a Weibull distribution with shape $c$ and scale $bg^{-1/a}(\mathbf{Z})$.

# Module 16 -- \# 3 

$$bg^{-1/a}(\mathbf{Z}) = b\phi \implies g(\mathbf{Z}) = \phi^{-a}$$

# Module 16 -- \# 4

$$e^{\alpha Z} = (e^{\beta Z})^{-a} \implies \alpha Z = -a \beta Z \implies \alpha = -a \beta$$

# Module 17 -- \# 1 Code

\tiny

```{r}
# load data
data("pharmacoSmoking")

# change survival times of 0 to greater than 0
pharmacoSmoking$ttr[pharmacoSmoking$ttr == 0] <- 0.001

# create survival object 
surv_obj_ps = Surv(pharmacoSmoking$ttr, pharmacoSmoking$relapse)

# run PH model 
ph_model = flexsurvreg(surv_obj_ps ~ grp + levelSmoking, 
                       data = pharmacoSmoking, 
                       dist = "exp")
ph_model
```

# Module 17 -- \# 1 Interpretation

Controlling for level of smoking, the hazard of relapse in the group with the patch only treatment is 2.19 times the hazard of relapse in the combination group.

# Module 17 -- \# 2 Code

\tiny

```{r}
# run AFT model 
aft_model = survreg(surv_obj_ps ~ grp + levelSmoking, 
                        data = pharmacoSmoking, 
                        dist = "exp")
aft_model %>% summary()
```

# Module 17 -- \# 2 Interpretation

Controlling for the level of smoking, the expected relapse time changes by a factor of 0.457 for those in the patch only treatment group compared to the combination group. In other words, the relapse time is 2.19 times accelerated in the patch only group compared to the combination group. 


# Module 17 -- \# 3

The coefficients are negated versions of one another. The hazard ratio and acceleration factor are equivalent.



