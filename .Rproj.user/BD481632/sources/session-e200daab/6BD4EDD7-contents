---
title: "BIOSTAT 702: Exercise 5"
subtitle: "Simple Linear Regression: Calculations"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  pdf_document:
    number_sections: false
    toc: true
    toc_depth: 3
    extra_dependencies: ["listings", "color"]
urlcolor: blue
header-includes: 
   - \usepackage{tabularx}
   - \usepackage{booktabs}
   - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
```

# Learning Objectives
\begin{enumerate}
  \item To practice some of the details around the various SLM calculations, including the derivation of the predictions and the ANOVA table.  Our premise is that by programming these yourself, one step at a time, you'll attain a deeper understanding of the content.
  \item To practice two types of R programming: (1) use of standard R functions to perform statistical analysis; and (2) use of matrices to perform calculations and create/extend statistical procedures.
\end{enumerate}

# How to Do This Exercise

We recommend that you read this entire document prior to answering any of the questions. If anything is unclear please ask for help from the instructors or TAs before getting started. You are also allowed to ask for help from the instructors or TAs while you are working on the assignment. You may collaborate with your classmates on this assignmentâ€”in fact, we encourage this--and use any technology resources available to you, including Internet searches, generative AI tools, etc. However, if you collaborate with others on this assignment please be aware that \textit{you must submit answers to the questions written in your own words. This means that you should not quote phrases from other sources, including AI tools, even with proper attribution.} Although quoting with proper attribution is good scholarly practice, it will be considered failure to follow the instructions for this assignment and you will be asked to revise and resubmit your answer. In this eventuality, points may be deducted in accordance with the grading rubric for this assignment as described below. Finally, you do not need to cite sources that you used to answer the questions for this assignment.


# Grading Rubric

The assignment is worth XXX points (4 points per question). The points for each question are awarded as follows: 3 points for answering all parts of the question and following directions, and 1 point for a correct answer. Partial credit may be awarded at the instructor's discretion.

# Preparation

We will use this toy dataset: 

# Question 1

\begin{enumerate}
\item Use the `matrix()` function in R to enter the elements of the toy datset. For example, the R coe for creating the toy dataset is `toy <- matrix(1, 1, 1, 1, 2, 3, 0, 4, 5, nrow = 3, ncol = 3)`. Print the results to verify.
\item Use the `colnames()` function to add column names of $X_0$, $X_1$, and $Y$. Print the results to verify. 
\item Apply the transpose operator to create $X'$ (You might have to call it $X_t$). Print the results to verify.
\item Use the matrix multiplication operator `%*%` to create $X'X$. Print the results to verify. Compare this with a hand calculation. For example, the top-left element of the matrix should be $1*1+1*1+1*1 = 3$. 
\item Use the `solve()` function to create $(X'X)^{-1}$ -- that is, the inverse of $X'X$. Verify that this inverse works as desired by multiplying it by $X'X$. What should the result be? 
\item Similarly, create $X'Y$. Print the results. 
\item Multiply $(X'X)^{-1}$ by $X'Y$. Name the resulting matrix Beta. Print Beta, which contains the parameter esimtaes from the SLR model. What are they? 
\end{enumerate}

# Question 2

\begin{enumerate}
\item Although it isn't absolutely necessary to do so, use the `data.frame()` function to create a data frame containing $X_1$ and $Y$. Name is XY.
\item Run a SLR on $XY$. First run the `lm()` function (taking care to appropriately name the variables) to create an output object named lm\_obj. Then run the `summary()` function on lm\_obj. Among others, a table of parameter estimates is printed. Do these parameter estimates match what you obtained using matrix operations? 
\item Although we will go into the composition of lm\_obj in more detail elsewhere, run the `names()` function to find the names of its components. How many components do you see? 
\item Print `lm_obj$coefficients`. What are the coefficients? 
\item In R code, how would you refer to the element of `lm_obj$coefficients` that contains $\beta_1$?
\item Using the information from `names()`, assign the fitted values to a new object named Fitted and print the results. 
\item Verify that the components of Fitted are identical to the result of applying the `predict()` function to lm\_obj. 
\item Check the calculation of the last fitted value -- it should be $-2.0 + (2.5*3)$. Is it? 
\end{enumerate}

# Question 3 

Now we will generate the inputs to the ANOVA table. 

\begin{enumerate}
\item The first task is to collect $Y, Y_m,$ and $Y_p$, all as 3 x 1 vectors. You already have $Y$ and $Y_p$. Calculate the mean of $Y$ and copy the results into a 3 x 1 vector using the `rep()` function. 
\item Create a vector that (1) calculates $Y-Y_m$; and then (2) squares the results. The `*` operator will be helpful. Sum the elements of this vector, and name the result SST. Check the calculation by hand. 
\item Create a vector that (1) calculates $Y-Y_p$; and then (2) squares the results. The `*` operator will be helpful. Sum the elements of this vector, and name the result SSE. Check the calculation by hand. 
\item Create a vector that (1) calculates $Y_p-Y_m$; and then (2) squares the results. The `*` operator will be helpful. Sum the elements of this vector, and name the result SSM. Check the calculation by hand.
\item You have now calculated the 3 sums of squares in the ANOVA table. What are their values? 
\item Generate an ANOVA table directly from lm\_obj by applying the `anova()` function. Do you obtain the same sums of squares? As a default, R doesn't print SST. From a statistical perspective, why not? 
\item How could you use the output object from the `anova()` function to calculate SST? Verify that your code works. 
\end{enumerate}

# Question 4 

You have already demonstrated that the results of applying the `lm() `function are identical to making the matrix calculations directly.  As a last set of tasks, check that these also match the algebraic version of the calculations.  Since we know that they do, you only need to check this for $\beta_1$.

$$\beta_1 = \frac{\sum_{i=1}^n (X_i-X_m)(Y_i-Y_m)}{\sum_{i=1}^n(X_i-X_m)^2}$$
Hack away at this problem one step at a time. For example, you have already created 3 copies of $Y_m$. Do the same for $X_m$, apply the `*` operator to perform the multiplications, and sum the results. Is $\beta_1$ as expected? 

# Question 5

This [site](https://zief0002.github.io/matrix-algebra/standard-errors-and-variance-estimates.html) walks you through using matrix algebra to create the variance-covariance matrix, the standard error of the regression coefficients, etc. You won't be asked to do all of this here.

This variance-covariance matrix contains the variance of $\beta_0$, the variance of $\beta_1$, and the covariance between $\beta_0$ and $\beta_1$.  We'll focus on the variance of $\beta_1$.  

\begin{enumerate}
\item The `vcov()` function in the `MASS` package calculates the variance-covariance matrix directly.  Apply this function to XY.  What is the value of the variance of $\beta_1$?  Take the square root of the variance of $\beta_1$.  Does it equal the standard error of the slope coefficient from summary(lm\_obj)?
\item Now consider the algebraic formula for $se(\beta_1): \{\sum_i(Y_i-Y_p)^2 / (n-2) \} / \sum_i(X_i-X_m)^2$.  The standard error is the square root of this.  You have already created most of the elements of this formula.  Verify that this formula yields an identical estimate of se($\beta_1$).
\item The formula contains 3 terms.  Here, $(n-2)$, the degrees of freedom associated with $\beta_1$, serves the purpose of appropriately accounting for the sample size. Considering $\sum_i(Y_i-Y_p)^2$, under what circumstances will this be small?  In particular, when the model fits well will this term be large or small?
\item Considering $\sum_i(X_i-X_m)^2$, under what circumstances will this be large?  When you are designing an experiment, and thus have the ability to assign the values of X, should they have a little variation or a lot of variation?  Remember: se($\beta_1$) will be small when the numerator is small and the denominator is large.   
\end{enumerate}

**Note:** BIOS701 will cover maximum likelihood estimation later in the semester.  For now, here is a brief summary.  Because the error terms are normally distributed so are the observations and so is $\beta_1$.  The likelihood function -- or, more simply, the log of the likelihood function -- quantifies the relative probability that the data will be observed, given a specific value of $\beta_1$.  The most likely value of $\beta_1$ is the maximum likelihood estimate (MLE).  At the MLE, the slope (i.e., first derivative) of the likelihood function will be 0.  If the likelihood function near the MLE is relatively flat, then a variety of values of $\beta_1$ are plausible, but if the likelihood function near the MLE is steep, then we can be confident that the observed MLE is close to the true value.  The steeper the slope, the more "information" is present, the smaller is se($\beta_1$), and the tighter will be the confidence interval for $\beta_1$.  The amount of information is influenced by the distribution of $X$, but is most strongly derived from how well the model fits -- in other words, how close $Y$ and $Y_p$ are.





