---
title: "BIOSTAT702 R Tutorial 2: "
subtitle: "One Sample Inference"
author: "Marissa Ashner, PhD"
date: "Last Updated: 2024-08-14"
output: 
  html_document:
    theme: cosmo
    fig_width: 7
    fig_height: 5
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
---

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}
h1.title{
  font-size: 30px;
  font-weight: bold;
  margin-bottom: 0px;
}
h1 {
  font-size: 20px;
}
h2{
  font-size: 16px;
}
h3.subtitle {
  font-size: 25px;
  font-style: italic;
  margin-top: 3px;
}
h3{
  font-size: 14px;
}
h4{
  font-size: 13px;
}
body, code.r, pre{
  font-size: 12px;
}
```


```{r setup, include=FALSE}
# setting global options for code chunks
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE)
```

This tutorial does not follow the 'usual'  [textbook](https://bookdown.org/rwnahhas/RMPH/datasumm.html), although we will use the datasets from the text for the examples.

# Packages 

The following code loads the packages you need for the tutorial.

```{r, message = FALSE}
## NOTE: If you do not have a package installed, you must install it first
# For example, you can run the following code if you don't have the gtsummary package:
# install.packages("gtsummary")


# for navigating within the R project
library(here)

# for data wrangling 
library(tidyverse)

# for CIs for one sample proportion tests
library(DescTools)

# for power analyses 
library(pwr)
library(pwrss)
```

# Resources

Below is a list of resources that may be helpful or provide more information on this topic. 

- [Power and Sample Size Calculations using `pwrss`](https://cran.r-project.org/web/packages/pwrss/vignettes/examples.html#11_Proportion(s)_(z_Test))
- [Power and Sample Size Calculations using `pwr`](https://www.statmethods.net/stats/power.html)

# Load Data 

```{r}
# Load Data 
# will be called "nhanes_adult_exam_sub" in your environment 
load(here("data/nhanes1718_adult_exam_sub_rmph.Rdata"))

# rename dataset for convenience 
nhanes <- nhanes_adult_exam_sub
```

# Binary Outcomes 

-   Let's say we are interested in estimating the proportion of people that have ever had 4/5+ drinks every day (variable `ALQ151` in the NHANES dataset) and testing whether this proportion is different than 10\%. 

## Examining the Data 

-   First, let's look at the sample proportion. 

```{r}
# take complete ALQ151 only
nhanes.binary = nhanes %>% filter(complete.cases(ALQ151))

prop.table(table(nhanes.binary$ALQ151))
```

## prop.test() vs. binom.test() 

-   There are two functions in R that can be used for inference involving proportions.
-   `prop.test()` uses a normal approximation to the binomial distribution and is generally used for larger sample sizes for that reason. 
    -   This function has the option to apply a continuity correction or not
-   `binom.test()` uses the exact binomial test and therefore outputs an exact p-value as well 

## Using prop.test()

### Two Sided Proportion Test 

-   Now, we can use the `prop.test()` function in R to test whether this proportion is different than 10\%. 
-   It should be noted that the Wilson's score method is used for the confidence interval for a one-sample test, which is different from the traditional Wald-type interval (as used in SAS), and it is known to have better coverage.
-   The `BinomCI()` function in the `DescTools` package can calculate the confidence interval both ways.

```{r}
# run the test
prop.test.twosided = prop.test(x = sum(nhanes.binary$ALQ151 == "Yes"), 
          n = nrow(nhanes.binary), 
          p = 0.1, 
          alternative = "two.sided", 
          correct = FALSE) # the 'correct' arugment applies a continuity correction by default, we are setting it equal to FALSE here

# print all the output
prop.test.twosided 

# print just the estimate 
prop.test.twosided$estimate

# print just the CI 
prop.test.twosided$conf.int

# print just the pvalue
prop.test.twosided$p.value

# compare wilson to wald CIs
BinomCI(x = sum(nhanes.binary$ALQ151 == "Yes"), 
        n = nrow(nhanes.binary), 
        sides = "two.sided", method = "wilson")
BinomCI(x = sum(nhanes.binary$ALQ151 == "Yes"), 
        n = nrow(nhanes.binary), 
        sides = "two.sided", method = "wald")
```

### One Sided Proportion Test

-   We instead want to test whether this proportion is *greater than* 10\%. We can alter our code using the `alternative` argument. 

```{r}
# run the test and print the output, without saving the output to a variable
prop.test(x = sum(nhanes.binary$ALQ151 == "Yes"), 
          n = nrow(nhanes.binary), 
          p = 0.1, 
          alternative = "greater", 
          correct = FALSE)
```

## Using binom.test() 

To show how to use this function, let's assume we have a sample proportion of 6/25, and we want to test if this is different than (or greater than for one-sided test) 4/25.

### One Sided Proportion Test 

For the one-sided test, you can see that the p-value is equivalent to calculating the percentage of successes greater than or equal to 6, under the null. 

```{r}
# run the binomial exact test
binom.test(6, 25, 4/25, alternative = "greater")

# check p-value 
# probability of getting 6 or more successes = 1-probability of 5 or less
1-pbinom(5, 25, 4/25)
```

### Two Sided Proportion Test 

For the two-sided test, the p-value in R is implemented by taking the upper tail p-value (what we calculated above) and adding to that the sum of lower-tail probabilities that are less than the probability of getting exactly 6 observed successes. See below for example. 

Note that different software calculate this two-sided p-value differently. 

```{r}
# run binomial test
binom.test(6, 25, 4/25, alternative = "two.sided")

# check p-value 
## calculate probability of exactly 6 observed under null 
d = dbinom(6, 25, 4/25)
d

## calculate floor of expected value under null (4 in our case) 
## calculate probability of 0, 1, 2, 3, 4 under null 
dbinom(c(0, 1, 2, 3, 4), 25, 4/25)

## since 0, 1 < d, include those in the p-value 
1-pbinom(5, 25, 4/25) + 
  pbinom(1, 25, 4/25)
```


## Power Calculation 

-   This follows the illustration from the notes. Assume that the true proportion is $\pi = 0.2$ and the proportion in the historical comparison group is $\pi = 0.15$. We want to calculate the power of detecting a difference from the comparison group. Assume $n = 100$. 

### Power Calculations via R functions 

-   There are several packages and several functions for power calculations of a one sample proportion in R. 
-   Exactly one of the parameters (effect size, sample size, power, and significance level) must be passed as NULL, and that one will be determined from the others. We will show an example calculating power from the other parameters, but it is also very common to calculate sample size from a known power parameter.

#### The `pwr` Package 

-   The `pwr.p.test()` function in the `pwr` package computes the power calculation for a one-sample proportion test. 
-   The `ES.h()` function to calculate the effect size uses an arcsine transformation. This is known to stabilize the variances.

```{r}
# using ES.h()
pwr.p.test(h = ES.h(0.2, 0.15), # effect size calculation
           n = 100, 
           alternative = "two.sided")
```

#### The `pwrss` Package 

-   The `pwrss.z.prop()` function in the `pwrss` package uses the normal approximation to compare the sample proportion to a proportion under the null hypothesis.
-   When `arcsin.trans = TRUE`, the result is equivalent to the result from the `pwr` package.

```{r}
# with arcsin 
pwrss.z.prop(p = 0.2, p0 = 0.15, 
             alpha = 0.05, n = 100, 
             alternative = "not equal",
             arcsin.trans = TRUE)

# without arcsin 
pwrss.z.prop(p = 0.2, p0 = 0.15, 
             alpha = 0.05, n = 100, 
             alternative = "not equal",
             arcsin.trans = FALSE)
```


### Power Calculations via Simulation 

-   Sometimes, it is of interest to do power calculations via simulation. This especially comes in handy for more complex situations when there are not R functions defined to calculate the power or sample size for your specific scenario. We will show an example of how to calculate the power of a proportion test using simulations. 
-   You can see this gives approximately the same power as the functions in R.

```{r}
# define function 
sim_func_proptest <- function(numsims){
  counter = 0
  # run the number of times as the user specifies
  for(i in 1:numsims){
    # set seed for reproducibility
    set.seed(i*1093)
    
    # simulate data 
    n = 100
    X = rbinom(n, size = 1, p = 0.2)
    
    # run t-test and grab p-value
    pval = prop.test(x = sum(X), n = n, p = 0.15,
                     alternative = "two.sided")$p.value
    
    # if effect is detected, save this iteration
    counter = ifelse(pval < 0.05, counter + 1, counter)
  }
  power = counter / numsims
  return(power)
}

# run function for 1000 iterations
sim_func_proptest(1000)
```


# Continuous Outcomes

-   Let's say we are interested in estimating the mean body weight (in kg) of the NHANES population (variable `BMXWT` in the NHANES dataset) and testing whether this mean is different than 83 kg. 

## Examining the Data 

-   Let's first take a look at the variable of interest, after limiting the sample to those with observed body weight. We can summarise the variable quantitatively and visually.

```{r}
# take complete BMXWT only
nhanes.bmxwt = nhanes %>% filter(complete.cases(BMXWT))

summary(nhanes.bmxwt$BMXWT)
```

```{r}
hist(nhanes.bmxwt$BMXWT)
```

## Two Sided T-Test 

-   We can use the `t.test()` function in R to test whether the mean body weight is different that 83 kg.

```{r}
# run the test 
bmxwt.test = t.test(x = nhanes.bmxwt$BMXWT, 
                    alternative = "two.sided", 
                    mu = 83)

# display all output from the test 
bmxwt.test

# print just the estimate 
bmxwt.test$estimate

# print just the CI 
bmxwt.test$conf.int

# print just the pvalue
bmxwt.test$p.value
```



## One Sided T-Test 

-   Now, we specifically want to test if the mean body weight is *greater* than 83 kg. This will be a one-sided test. The alteration to the R code is the same as for a one sample proportion test. 

```{r}
# run the test 
bmxwt.test.onesided = t.test(x = nhanes.bmxwt$BMXWT, 
                    alternative = "greater", 
                    mu = 83)

# display all output from the test 
bmxwt.test.onesided
```

## Power Calculation

-   Assume that the true mean is $\mu = 50$ and we want to calculate the power of detecting a difference from the alternative $\mu_0 = 49.5$. Assume $n = 50$.

### Power Calculations via R functions 

-   There are several packages and several functions for power calculations of a one sample continuous variable in R. 
-   Exactly one of the parameters (effect size, sample size, power, and significance level) must be passed as NULL, and that one will be determined from the others. We will show an example calculating power from the other parameters, but it is also very common to calculate sample size from a known power parameter.
-   There are power calculation functions for both t-tests and z-tests. 

#### The `pwr` Package 

-   The `pwr` package has the `pwr.norm.test()` function and the `pwr.t.test()` function. 
-   The `pwr.norm.test()` computes the power calculations for the mean of a normal distribution with known variance. 
-   The `pwr.t.test()` computes the power calculations for t-tests of means. 
-   The effect size in these function includes division by the standard deviation. If you just include the difference between $\mu$ and $\mu_0$, it's assumed the standard deviation is 1.

```{r}
# power calculation using pwr.norm.test() 
pwr.norm.test(d = 50 - 49.5, # the effect size mu - mu0 / sd
              n = 50, 
              sig.level = 0.05, 
              alternative = "two.sided")

# power calculation using pwr.t.test()
pwr.t.test(d = 50-49.5, # the effect size mu - mu0 / sd
           n = 50, 
           sig.level = 0.05, 
           type = "one.sample", 
           alternative = "two.sided")
```

#### The `stats` Package 

-   This package is in base R and does not need to be installed. 
-   The `power.t.test()` function is another way to compute the same thing that was done in the `pwr.t.test()` function. You can see the results are identical.

```{r}
# power calculation using power.t.test from the stats package
stats::power.t.test(n = 50, 
                    delta = 50-49.5, 
                    sd = 1, 
                    type = "one.sample", 
                    alternative = "two.sided")
```

#### The `pwrss` Package 

-   The `power.t.test()` and `power.z.test()` functions in the `pwrss` package provides nice visuals for the power analyses. The t-test function does have the same name as the one from the `stats` package, so be careful to specify which you are using.
-   You can see the results below are the same as the other two t-test and z-tests functions.

```{r}
# t-test using the pwrss package
pwrss::power.t.test(ncp = (50-49.5)/(1/sqrt(50)), 
                    # effect size mu - mu0 / (sd / sqrt(n))
                    df = 50-1, 
                    alpha = 0.05, 
                    alternative = "not equal", 
                    plot = TRUE)

# z-test using the pwrss package
pwrss::power.z.test(ncp = (50-49.5)/(1/sqrt(50)), 
                    # effect size mu - mu0 / (sd / sqrt(n))
                    alpha = 0.05, 
                    alternative = "not equal", 
                    plot = TRUE)
```

### Power Calculations via Simulation 

-   Sometimes, it is of interest to do power calculations via simulation. This especially comes in handy for more complex situations when there are not R functions defined to calculate the power or sample size for your specific scenario. We will show an example of how to calculate the power of a t-test using simulations. 
-   You can see this gives approximately the same power as the functions in R.

```{r}
# define function 
sim_func_ttest <- function(numsims){
  counter = 0
  # run the number of times as the user specifies
  for(i in 1:numsims){
    # set seed for reproducibility
    set.seed(i*1093)
    
    # simulate data 
    n = 50
    X = rnorm(n, 50, 1)
    
    # run t-test and grab p-value
    pval = t.test(x = X, mu = 49.5, alternative = "two.sided")$p.value
    
    # if effect is detected, save this iteration
    counter = ifelse(pval < 0.05, counter + 1, counter)
  }
  power = counter / numsims
  return(power)
}

# run function for 1000 iterations
sim_func_ttest(1000)
```


# Session information

```{r echo = FALSE, results = 'markup'}
sessionInfo()
```

